{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!python -m spacy download pt_core_news_sm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iuRVuRuFSle",
        "outputId": "0dec5072-eb7c-438f-f7b1-9e8c375ebb4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pt-core-news-sm==3.7.0\n",
            "  Downloading https://github.com/explosion/spacy-models/releases/download/pt_core_news_sm-3.7.0/pt_core_news_sm-3.7.0-py3-none-any.whl (13.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m32.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /usr/local/lib/python3.10/dist-packages (from pt-core-news-sm==3.7.0) (3.7.5)\n",
            "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.12)\n",
            "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.0.5)\n",
            "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.0.10)\n",
            "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.0.8)\n",
            "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.9)\n",
            "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (8.2.5)\n",
            "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.1.3)\n",
            "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.4.8)\n",
            "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.0.10)\n",
            "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.4.1)\n",
            "Requirement already satisfied: typer<1.0.0,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.12.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (4.66.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.31.0)\n",
            "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.8.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.1.4)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (67.7.2)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (24.1)\n",
            "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.4.0)\n",
            "Requirement already satisfied: numpy>=1.19.0 in /usr/local/lib/python3.10/dist-packages (from spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.25.2)\n",
            "Requirement already satisfied: language-data>=1.2 in /usr/local/lib/python3.10/dist-packages (from langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.20.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.20.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2024.7.4)\n",
            "Requirement already satisfied: blis<0.8.0,>=0.7.8 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.7.11)\n",
            "Requirement already satisfied: confection<1.0.0,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.1.5)\n",
            "Requirement already satisfied: click>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (8.1.7)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /usr/local/lib/python3.10/dist-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (13.7.1)\n",
            "Requirement already satisfied: cloudpathlib<1.0.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.18.1)\n",
            "Requirement already satisfied: smart-open<8.0.0,>=5.2.1 in /usr/local/lib/python3.10/dist-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (7.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.1.5)\n",
            "Requirement already satisfied: marisa-trie>=0.7.7 in /usr/local/lib/python3.10/dist-packages (from language-data>=1.2->langcodes<4.0.0,>=3.2.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.2.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (2.16.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.10/dist-packages (from smart-open<8.0.0,>=5.2.1->weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (1.14.1)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.0->pt-core-news-sm==3.7.0) (0.1.2)\n",
            "Installing collected packages: pt-core-news-sm\n",
            "Successfully installed pt-core-news-sm-3.7.0\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the package via spacy.load('pt_core_news_sm')\n",
            "\u001b[38;5;3m⚠ Restart to reload dependencies\u001b[0m\n",
            "If you are in a Jupyter or Colab notebook, you may need to restart Python in\n",
            "order to load all the package's dependencies. You can do this by selecting the\n",
            "'Restart kernel' or 'Restart runtime' option.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from gensim.models import KeyedVectors"
      ],
      "metadata": {
        "id": "fQM7LPRnE-5C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Pkhy0pJ8-31O"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from gensim.models import KeyedVectors\n",
        "#Caregando modelos\n",
        "w2v_modelo_cbow = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/Alura/ML_Avançada/NLP/modelo_cbow.txt')\n",
        "w2v_modelo_sg = KeyedVectors.load_word2vec_format('/content/drive/MyDrive/Alura/ML_Avançada/NLP/modelo_skipgram.txt')\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "artigo_treino = pd.read_csv('/content/drive/MyDrive/Alura/ML_Avançada/NLP/treino.csv')\n",
        "artigo_teste = pd.read_csv('/content/drive/MyDrive/Alura/ML_Avançada/NLP/teste.csv')"
      ],
      "metadata": {
        "id": "kqjFgLsh-5iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Função tokenizador\n",
        "- doc = nlp(texto):\n",
        "\n",
        "- A variável doc contém o texto processado pelo modelo spaCy.\n",
        "\n",
        "- tokens_validos = []:\n",
        "Esta lista armazenará os tokens que atendem aos critérios de validação.\n",
        "for token in doc:\n",
        "\n",
        "- Este loop percorre cada token no documento processado.\n",
        "\n",
        "- e_valido = not token.is_stop and token.is_alpha:\n",
        "\n",
        "- token.is_stop verifica se o token é uma stop word (palavra muito comum que geralmente é ignorada no processamento de linguagem natural).\n",
        "\n",
        "- token.is_alpha verifica se o token é composto apenas por caracteres alfabéticos (ou seja, não contém números ou caracteres especiais).\n",
        "\n",
        "- e_valido será True apenas se o token não for uma stop word e for composto apenas por letras.\n",
        "\n",
        "- if e_valido: tokens_validos.append(token.text.lower()):\n",
        "Se o token for válido, ele é convertido para minúsculas e adicionado à lista tokens_validos.\n",
        "return tokens_validos:\n",
        "\n",
        "- A função retorna a lista de tokens válidos."
      ],
      "metadata": {
        "id": "xtQQE5ZsNiNT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nlp = spacy.load(\"pt_core_news_sm\", disable=[\"paser\", \"ner\", \"tagger\", \"textcat\"])\n",
        "\n",
        "def tokenizador(texto):\n",
        "\n",
        "    doc = nlp(texto)\n",
        "    tokens_validos = []\n",
        "    for token in doc:\n",
        "        e_valido = not token.is_stop and token.is_alpha\n",
        "        if e_valido:\n",
        "            tokens_validos.append(token.text.lower())\n",
        "\n",
        "\n",
        "    return  tokens_validos\n",
        "\n",
        "texto = \"Rio de Janeiro 1231231 ***** @#$ é uma cidade maravilhosa!\"\n",
        "tokens = tokenizador(texto)\n",
        "print(tokens)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTt_JmKjFE-4",
        "outputId": "448de86b-5b77-48f1-8d51-266492c9873d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['rio', 'janeiro', 'cidade', 'maravilhosa']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Função combinação de vetores por soma"
      ],
      "metadata": {
        "id": "91TUAQG6OPAB"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Aqui, a função cria um vetor de zeros de dimensão (1, 300). Esse vetor será usado para acumular a soma dos vetores das palavras. O tamanho 300 é escolhido assumindo que os vetores no modelo têm 300 dimensões. Se o modelo tiver vetores de uma dimensão diferente, esse número deve ser ajustado.\n",
        "\n",
        "- for pn in palavras:: Itera sobre cada palavra na lista de palavras.\n",
        "- try:: Tenta obter o vetor da palavra no modelo.\n",
        "- vetor_resultante += modelo.get_vector(pn): Se a palavra estiver no vocabulário do modelo, o vetor correspondente é somado ao vetor_resultante.\n",
        "- except KeyError:: Se a palavra não estiver no vocabulário do modelo, um KeyError é levantado, e o código simplesmente ignora essa palavra (pass)."
      ],
      "metadata": {
        "id": "qVWEs6C-N-Wl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def combinacao_de_vetores_por_soma(palavras, modelo):\n",
        "\n",
        "    vetor_resultante = np.zeros((1,300))\n",
        "\n",
        "    for pn in palavras:\n",
        "        try:\n",
        "            vetor_resultante += modelo.get_vector(pn)\n",
        "\n",
        "        except KeyError:\n",
        "            pass\n",
        "\n",
        "\n",
        "    return vetor_resultante\n",
        "\n",
        "vetor_texto = combinacao_de_vetores_por_soma(tokens, w2v_modelo_cbow)\n",
        "print(vetor_texto.shape)\n",
        "print(vetor_texto)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ShKlwiJsFHMI",
        "outputId": "4684908e-2322-4d6f-e97d-d0a5f98ad963"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(1, 300)\n",
            "[[-0.27450757 -0.59825522  0.69133548 -1.13243518  0.18720647  2.12337512\n",
            "  -1.84139195  0.74638875  0.23407404 -0.04284739  1.10862119  0.89352629\n",
            "  -2.31446788 -0.47999281  0.87822711 -2.21164209 -0.25529537 -1.24711985\n",
            "   0.68264387  0.89696053 -0.30993313 -1.39740703 -0.1914977   0.07912045\n",
            "   0.27154632 -2.1578359   0.50183762 -1.02607948 -0.41872717  1.54443856\n",
            "  -0.50024045 -1.71675737  1.23583828  2.47640713  1.589202    0.08996588\n",
            "  -2.01210493 -0.42342442  0.06255623 -0.38721713 -0.63647851  1.03961195\n",
            "   1.279463   -1.52828383 -2.22172838 -0.11052847  1.96253443 -0.7456958\n",
            "   1.66987214 -0.15660812 -1.42984989 -1.97375983  0.82749984 -1.95111883\n",
            "  -0.58955556  1.14995566  0.86756    -1.33911222  1.42421293  1.32092891\n",
            "  -1.1612137  -2.22032329  1.79152638 -0.34962308  0.98687069  0.12655459\n",
            "   0.41527253  0.40892041  0.11260994 -0.50725175  1.38428345  2.05934276\n",
            "  -0.32172359  0.1001855   0.88106175  1.32230061  1.4537811   0.40400892\n",
            "  -1.92261148  1.0899249  -1.22398871  2.676817   -0.85827961  2.7680316\n",
            "  -0.14286146 -1.35122565  0.34544954  2.11366555  0.22142804  0.17597404\n",
            "  -0.4097466  -0.79717514 -0.24001656 -2.1589703  -0.32848999  1.72607973\n",
            "   2.07936029  0.90085539 -0.73707053  1.4750475   0.9393983   0.93073551\n",
            "   0.69095914 -0.8085095  -0.47493251  1.47809845 -0.98759575  1.80604529\n",
            "  -1.07823546 -0.42520887 -0.52926456 -0.31209611  0.70357507 -0.90203591\n",
            "   1.41016018 -0.39801402  1.18552323 -0.13956682 -1.42286332 -1.3274093\n",
            "   1.91010331  0.12153056  1.36430687  0.70369048  0.84781281  4.18214059\n",
            "  -1.49810621 -3.03030252  0.32896787  4.01571363  2.58219975 -0.48067364\n",
            "   0.92601725 -0.59502414 -0.5663016  -2.43971312 -0.47551572  2.21257111\n",
            "  -1.36413682 -0.66535708 -1.5939714  -1.30020547  2.46840584  0.87964317\n",
            "   1.25761571 -1.21897297 -2.04078637  0.20470807  0.38015776  0.80395825\n",
            "  -1.14505333 -3.29330843 -1.70796582 -0.83713076  2.20429364  0.76202171\n",
            "   0.62075931 -0.45293471  0.33657053  3.57547861  0.91376895  1.91416317\n",
            "   1.93701145 -0.82448699  2.0312186   1.06409065  0.4206294   0.44622713\n",
            "   0.80897101  0.5613956   0.4455955  -0.59522923 -0.54949925  0.07126988\n",
            "  -0.40457632  0.6779258   0.93652918  1.07921823  2.01849639 -1.18688444\n",
            "  -0.05327399 -0.14902344 -0.28814751 -1.13304994  1.3692946  -0.25174636\n",
            "  -0.22364126  1.36492634  1.4733095  -0.33443555 -0.59682712  2.40418291\n",
            "  -0.10775822  0.80429962 -2.55663973  0.31275462  1.36828823 -1.18539702\n",
            "   0.56430322 -0.31740785 -1.16258513  1.9755359  -1.36173004  0.68027963\n",
            "   1.08921212 -0.6077331   1.40775037  0.46111056  1.71726078 -1.83224155\n",
            "  -0.15250363 -0.55846433 -0.84745278 -0.66771919 -1.93147367  0.18601128\n",
            "   0.73925859  0.18530934 -0.62604478 -2.73526657  0.24479553  0.94665131\n",
            "   0.5508172  -0.94478478 -2.34124804  1.6630117   0.42582613 -1.51812752\n",
            "  -1.66615798 -0.2149823  -2.23425716 -2.78264683  2.29067662 -0.49300754\n",
            "  -0.39658542 -1.2683413  -0.25909807 -0.88551041  1.6486789  -0.18727054\n",
            "   1.34067787  0.28827834  2.42211803 -2.37618881  1.95294553 -1.39286673\n",
            "  -0.54532181 -0.21256822 -0.99681014 -1.19716138  0.70342179  1.97905087\n",
            "   1.95312714 -2.64674965 -2.15004972 -1.69354477  1.05413508 -0.99613152\n",
            "  -3.01268199 -2.36992162  0.29148182 -0.6358481   1.23051512  0.63481766\n",
            "  -0.58663827 -0.69408952 -0.51371649 -0.74060997 -3.71228164 -5.48965883\n",
            "  -1.50760689  1.18978357  0.29546805 -0.05978282  1.02619331  1.23135021\n",
            "   1.86354157  0.8282752  -0.25582367 -1.00926307 -1.01952132  0.45144865\n",
            "  -0.66784815 -1.02975279  3.95667651 -0.50449556 -1.48683277 -2.94833612\n",
            "  -0.71485171 -0.09978443 -0.57600588  1.12350199  0.81647465  0.98927474\n",
            "   0.61639617 -1.03424166 -0.26719397  1.41304573  0.74838063  1.64687845]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Função matriz vetores\n",
        "\n",
        "- x é o número de textos.\n",
        "- y é o tamanho dos vetores no modelo (neste caso, assumindo 300 dimensões).\n",
        "- matriz é uma matriz de zeros com dimensão (x, 300).\n",
        "- for i in range(x): itera sobre cada texto.\n",
        "- palavras = tokenizador(textos.iloc[i]) tokeniza o texto na posição i usando a função tokenizador.\n",
        "- matriz[i] = combinacao_de_vetores_por_soma(palavras, modelo) calcula a soma dos vetores das palavras no texto e armazena o resultado na i-ésima linha da matriz."
      ],
      "metadata": {
        "id": "GSweKAiAOTIo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def matriz_vetores(textos, modelo):\n",
        "    x = len(textos)\n",
        "    y = 300\n",
        "    matriz = np.zeros((x,y))\n",
        "\n",
        "    for i in range(x):\n",
        "        palavras = tokenizador(textos.iloc[i])\n",
        "        matriz[i] = combinacao_de_vetores_por_soma(palavras, modelo)\n",
        "\n",
        "    return matriz\n",
        "\n",
        "matriz_vetores_treino_cbow = matriz_vetores(artigo_treino.title, w2v_modelo_cbow)\n",
        "matriz_vetores_teste_cbow = matriz_vetores(artigo_teste.title, w2v_modelo_cbow)\n",
        "print(matriz_vetores_treino_cbow.shape)\n",
        "print(matriz_vetores_teste_cbow.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k_hkxSQlFIqa",
        "outputId": "1a5b4a20-d0d0-4951-d2da-2c27a0db1c0e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(90000, 300)\n",
            "(20513, 300)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Treinamento dos modelos"
      ],
      "metadata": {
        "id": "95BqeN2pOoQy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modelo cbow"
      ],
      "metadata": {
        "id": "cQ-PwZjRI8N7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "def classificador(modelo, x_treino, y_treino, x_teste, y_teste):\n",
        "\n",
        "    RL = LogisticRegression(max_iter = 800)\n",
        "    RL.fit(x_treino, y_treino)\n",
        "    categorias = RL.predict(x_teste)\n",
        "    resultados = classification_report(y_teste, categorias)\n",
        "    print(resultados)\n",
        "\n",
        "    return RL\n",
        "\n",
        "RL_cbow = classificador(w2v_modelo_cbow,\n",
        "                        matriz_vetores_treino_cbow,\n",
        "                        artigo_treino.category,\n",
        "                        matriz_vetores_teste_cbow,\n",
        "                        artigo_teste.category)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KcR24g9eFW6n",
        "outputId": "9c0c66b9-95fd-4f74-976e-0286e30a4df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     colunas       0.80      0.71      0.75      6103\n",
            "   cotidiano       0.64      0.80      0.71      1698\n",
            "     esporte       0.92      0.86      0.89      4663\n",
            "   ilustrada       0.13      0.86      0.23       131\n",
            "     mercado       0.84      0.78      0.81      5867\n",
            "       mundo       0.74      0.84      0.79      2051\n",
            "\n",
            "    accuracy                           0.79     20513\n",
            "   macro avg       0.68      0.81      0.70     20513\n",
            "weighted avg       0.82      0.79      0.80     20513\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Modelo SkipGram"
      ],
      "metadata": {
        "id": "ZkjGyzhdI-gC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "matriz_vetores_treino_sg = matriz_vetores(artigo_treino.title, w2v_modelo_sg)\n",
        "matriz_vetores_teste_sg = matriz_vetores(artigo_teste.title, w2v_modelo_sg)\n",
        "\n",
        "RL_sg = classificador(w2v_modelo_sg,\n",
        "                        matriz_vetores_treino_sg,\n",
        "                        artigo_treino.category,\n",
        "                        matriz_vetores_teste_sg,\n",
        "                        artigo_teste.category)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lfrY7FYaIgSV",
        "outputId": "3eef6b2d-f3d7-4618-d7e6-d8022b128046"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "     colunas       0.80      0.71      0.76      6103\n",
            "   cotidiano       0.65      0.81      0.72      1698\n",
            "     esporte       0.93      0.87      0.90      4663\n",
            "   ilustrada       0.14      0.89      0.24       131\n",
            "     mercado       0.84      0.79      0.82      5867\n",
            "       mundo       0.75      0.84      0.79      2051\n",
            "\n",
            "    accuracy                           0.79     20513\n",
            "   macro avg       0.69      0.82      0.70     20513\n",
            "weighted avg       0.82      0.79      0.80     20513\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Modelos com resultados bem parecidos."
      ],
      "metadata": {
        "id": "X5lnuyo0MkCu"
      }
    }
  ]
}